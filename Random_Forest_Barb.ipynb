{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is using data prep/encoding that we decided upon for group project.  We have divided algorithm analysis up between members and want to have uniform data prep/encoding for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"bank-additional-full.csv\")\n",
    "#inital EDA showed strong correlation for emp.var.rate/nr.employed with euribor3m, duration can't know ahead of time, also drop\n",
    "dataset = dataset.drop(['emp.var.rate','nr.employed', 'duration'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'campaign', 'pdays', 'previous',\n",
       "       'poutcome', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 18)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  campaign  pdays  previous     poutcome  cons.price.idx  \\\n",
       "0   may         mon         1    999         0  nonexistent          93.994   \n",
       "1   may         mon         1    999         0  nonexistent          93.994   \n",
       "2   may         mon         1    999         0  nonexistent          93.994   \n",
       "3   may         mon         1    999         0  nonexistent          93.994   \n",
       "4   may         mon         1    999         0  nonexistent          93.994   \n",
       "\n",
       "   cons.conf.idx  euribor3m   y  \n",
       "0          -36.4      4.857  no  \n",
       "1          -36.4      4.857  no  \n",
       "2          -36.4      4.857  no  \n",
       "3          -36.4      4.857  no  \n",
       "4          -36.4      4.857  no  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 18 columns):\n",
      "age               41188 non-null int64\n",
      "job               41188 non-null object\n",
      "marital           41188 non-null object\n",
      "education         41188 non-null object\n",
      "default           41188 non-null object\n",
      "housing           41188 non-null object\n",
      "loan              41188 non-null object\n",
      "contact           41188 non-null object\n",
      "month             41188 non-null object\n",
      "day_of_week       41188 non-null object\n",
      "campaign          41188 non-null int64\n",
      "pdays             41188 non-null int64\n",
      "previous          41188 non-null int64\n",
      "poutcome          41188 non-null object\n",
      "cons.price.idx    41188 non-null float64\n",
      "cons.conf.idx     41188 non-null float64\n",
      "euribor3m         41188 non-null float64\n",
      "y                 41188 non-null object\n",
      "dtypes: float64(3), int64(4), object(11)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Initial data prep\n",
    "#check for null values\n",
    "#dataset.isnull().values.any()\n",
    "#remove rows with >= 4 unkown values\n",
    "#dataset = dataset.replace(to_replace='unknown', value=np.nan).dropna(thresh=17)\n",
    "#dataset = dataset.replace(to_replace='unknown', value=np.nan).dropna()\n",
    "#dataset = dataset.replace(to_replace=np.nan, value='unknown')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['basic.4y', 'high.school', 'basic.6y', 'basic.9y',\n",
       "       'professional.course', 'unknown', 'university.degree',\n",
       "       'illiterate'], dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Basic', 'high.school', 'professional.course', 'unknown',\n",
       "       'university.degree', 'illiterate'], dtype=object)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['education']=np.where(dataset['education'] =='basic.9y', 'Basic', dataset['education'])\n",
    "dataset['education']=np.where(dataset['education'] =='basic.6y', 'Basic', dataset['education'])\n",
    "dataset['education']=np.where(dataset['education'] =='basic.4y', 'Basic', dataset['education'])\n",
    "dataset['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding all Catergorical Variables without Order\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.BinaryEncoder(cols=['job','marital','education','default','housing','loan','contact','poutcome','month','day_of_week'])\n",
    "#encoder = ce.BinaryEncoder(cols=['job','marital','default','housing','loan','contact','poutcome','month','day_of_week'])\n",
    "dataset = encoder.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Outcome Row to Binary\n",
    "#dataset['outcome'] = dataset['outcome'].map({'yes': 1, 'no': 0})\n",
    "dataset['y'] = dataset['y'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 43)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  51158\n",
      "Number of no term in oversampled data 25579\n",
      "Number of term 25579\n",
      "Proportion of no term data in oversampled data is  0.5\n",
      "Proportion of term data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "#balance using SMOTE\n",
    "X = dataset.loc[:, dataset.columns != 'y']\n",
    "y = dataset.loc[:, dataset.columns == 'y']\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "os_data_X,os_data_y = os.fit_sample(X_train, y_train.values.ravel())\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no term in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"Number of term\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"Proportion of no term data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"Proportion of term data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))\n",
    "X = os_data_X\n",
    "y = os_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into Training Set and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12856838 0.07256526 0.06849373 0.06163101 0.05756351 0.05612562\n",
      " 0.05355602 0.05161025 0.04877781 0.0465348  0.03949361 0.03358003\n",
      " 0.03201337 0.03065358 0.02941269 0.02733616 0.02650904 0.02515889\n",
      " 0.01779195 0.01743848 0.01575864 0.01317584 0.00803633 0.00726025\n",
      " 0.00708338 0.00596055 0.00526197 0.0049535  0.00364978 0.00358439\n",
      " 0.00045829]\n",
      "[0.12856838 0.20113364 0.26962737 0.33125838 0.38882189 0.44494751\n",
      " 0.49850353 0.55011378 0.59889159 0.64542639 0.68492001 0.71850004\n",
      " 0.75051341 0.78116699 0.81057968 0.83791584 0.86442488 0.88958377\n",
      " 0.90737572 0.92481419 0.94057284 0.95374868 0.96178502 0.96904526\n",
      " 0.97612864 0.98208919 0.98735116 0.99230466 0.99595444 0.99953884\n",
      " 0.99999712]\n"
     ]
    }
   ],
   "source": [
    "#Applying PCA\n",
    "#First we want to including all principle components by specifying None\n",
    "from sklearn.decomposition import PCA\n",
    "#start with None, then eval\n",
    "pcaObj= PCA(n_components=31)\n",
    "X_train= pcaObj.fit_transform(X_train)\n",
    "X_test= pcaObj.transform(X_test)\n",
    "#show components and what is most important, then decid on n_components\n",
    "components_variance = pcaObj.explained_variance_ratio_\n",
    "cumulative_variance = pcaObj.explained_variance_ratio_.cumsum()\n",
    "print(components_variance)\n",
    "print(cumulative_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "#max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "#min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "#bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "#random_grid = {'n_estimators': n_estimators,\n",
    "#               'max_features': max_features,\n",
    "#               'max_depth': max_depth,\n",
    "#               'min_samples_split': min_samples_split,\n",
    "#               'min_samples_leaf': min_samples_leaf,\n",
    "#               'bootstrap': bootstrap}\n",
    "#print(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "#classifierObj = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "#classifierObj_random = RandomizedSearchCV(estimator = classifierObj, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "#classifierObj_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifierObj_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Classifier to Training Set. Create a classifier object here and call it classifierObj\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#classifierObj= RandomForestClassifier()\n",
    "#grid_param= {  \n",
    "#    'n_estimators': [10, 15, 20, 25, 30, 40, 50],\n",
    "#    'criterion': ['gini', 'entropy'],\n",
    "#    'bootstrap': [True, False],\n",
    "#    'max_depth': [5, 10, 20, 30]\n",
    "#}\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#gd_sr= GridSearchCV(estimator=classifierObj, param_grid=grid_param, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "#gd_sr.fit(X_train, y_train) \n",
    "#print(gd_sr.best_params_) #print(gd_sr.best_score_)\n",
    "\n",
    "#grid search results {'bootstrap': False, 'criterion': 'gini', 'max_depth': 10, 'n_estimators': 40}\n",
    "#0.8942943854324734\n",
    "classifierObj= RandomForestClassifier(bootstrap=True, criterion='gini', max_depth= 10, n_estimators=40)\n",
    "classifierObj.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7859794250174938\n",
      "0.007847028490305875\n"
     ]
    }
   ],
   "source": [
    "#K-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "modelAccuracies = cross_val_score(estimator=classifierObj, X=X_train, y=y_train.values.ravel(), cv=10)\n",
    "print(modelAccuracies.mean())\n",
    "print(modelAccuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4736  369]\n",
      " [ 550 4577]]\n"
     ]
    }
   ],
   "source": [
    "#Making predictions on the Test Set\n",
    "y_pred = classifierObj.predict(X_test)\n",
    "\n",
    "#Evaluating the predictions using a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score = classifierObj.score(X_test, y_test)\n",
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
